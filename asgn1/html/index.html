<html><head><title>CSCI3290 - Assignment 1</title><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_t3ytwd7v5c9j-2>li{counter-increment:lst-ctn-kix_t3ytwd7v5c9j-2}.lst-kix_t3ytwd7v5c9j-0>li:before{content:"" counter(lst-ctn-kix_t3ytwd7v5c9j-0,decimal) ". "}ol.lst-kix_t3ytwd7v5c9j-5.start{counter-reset:lst-ctn-kix_t3ytwd7v5c9j-5 0}.lst-kix_t3ytwd7v5c9j-8>li:before{content:"" counter(lst-ctn-kix_t3ytwd7v5c9j-8,lower-roman) ". "}.lst-kix_t3ytwd7v5c9j-0>li{counter-increment:lst-ctn-kix_t3ytwd7v5c9j-0}.lst-kix_t3ytwd7v5c9j-3>li:before{content:"" counter(lst-ctn-kix_t3ytwd7v5c9j-3,decimal) ". "}.lst-kix_t3ytwd7v5c9j-7>li:before{content:"" counter(lst-ctn-kix_t3ytwd7v5c9j-7,lower-latin) ". "}ol.lst-kix_t3ytwd7v5c9j-3.start{counter-reset:lst-ctn-kix_t3ytwd7v5c9j-3 0}ol.lst-kix_t3ytwd7v5c9j-0{list-style-type:none}ol.lst-kix_t3ytwd7v5c9j-1{list-style-type:none}.lst-kix_t3ytwd7v5c9j-4>li:before{content:"" counter(lst-ctn-kix_t3ytwd7v5c9j-4,lower-latin) ". "}ol.lst-kix_t3ytwd7v5c9j-0.start{counter-reset:lst-ctn-kix_t3ytwd7v5c9j-0 0}ol.lst-kix_t3ytwd7v5c9j-2.start{counter-reset:lst-ctn-kix_t3ytwd7v5c9j-2 0}.lst-kix_t3ytwd7v5c9j-1>li:before{content:"" counter(lst-ctn-kix_t3ytwd7v5c9j-1,lower-latin) ". "}.lst-kix_t3ytwd7v5c9j-5>li:before{content:"" counter(lst-ctn-kix_t3ytwd7v5c9j-5,lower-roman) ". "}.lst-kix_t3ytwd7v5c9j-2>li:before{content:"" counter(lst-ctn-kix_t3ytwd7v5c9j-2,lower-roman) ". "}ol.lst-kix_t3ytwd7v5c9j-6.start{counter-reset:lst-ctn-kix_t3ytwd7v5c9j-6 0}.lst-kix_t3ytwd7v5c9j-7>li{counter-increment:lst-ctn-kix_t3ytwd7v5c9j-7}.lst-kix_t3ytwd7v5c9j-1>li{counter-increment:lst-ctn-kix_t3ytwd7v5c9j-1}.lst-kix_t3ytwd7v5c9j-4>li{counter-increment:lst-ctn-kix_t3ytwd7v5c9j-4}.lst-kix_t3ytwd7v5c9j-6>li:before{content:"" counter(lst-ctn-kix_t3ytwd7v5c9j-6,decimal) ". "}.lst-kix_t3ytwd7v5c9j-8>li{counter-increment:lst-ctn-kix_t3ytwd7v5c9j-8}ol.lst-kix_t3ytwd7v5c9j-1.start{counter-reset:lst-ctn-kix_t3ytwd7v5c9j-1 0}.lst-kix_t3ytwd7v5c9j-6>li{counter-increment:lst-ctn-kix_t3ytwd7v5c9j-6}ol.lst-kix_t3ytwd7v5c9j-8.start{counter-reset:lst-ctn-kix_t3ytwd7v5c9j-8 0}ol.lst-kix_t3ytwd7v5c9j-8{list-style-type:none}ol.lst-kix_t3ytwd7v5c9j-7.start{counter-reset:lst-ctn-kix_t3ytwd7v5c9j-7 0}ol.lst-kix_t3ytwd7v5c9j-6{list-style-type:none}ol.lst-kix_t3ytwd7v5c9j-7{list-style-type:none}ol.lst-kix_t3ytwd7v5c9j-4{list-style-type:none}.lst-kix_t3ytwd7v5c9j-3>li{counter-increment:lst-ctn-kix_t3ytwd7v5c9j-3}ol.lst-kix_t3ytwd7v5c9j-5{list-style-type:none}.lst-kix_t3ytwd7v5c9j-5>li{counter-increment:lst-ctn-kix_t3ytwd7v5c9j-5}ol.lst-kix_t3ytwd7v5c9j-2{list-style-type:none}ol.lst-kix_t3ytwd7v5c9j-4.start{counter-reset:lst-ctn-kix_t3ytwd7v5c9j-4 0}ol.lst-kix_t3ytwd7v5c9j-3{list-style-type:none}ol{margin:0;padding:0}.c17{vertical-align:top;width:90pt;border-style:solid;border-color:#000000;border-width:1pt;padding:5pt 5pt 5pt 5pt}.c10{vertical-align:top;width:129.2pt;border-style:solid;border-color:#000000;border-width:1pt;padding:5pt 5pt 5pt 5pt}.c13{vertical-align:top;width:80.2pt;border-style:solid;border-color:#000000;border-width:1pt;padding:5pt 5pt 5pt 5pt}.c8{vertical-align:top;width:97.8pt;border-style:solid;border-color:#000000;border-width:1pt;padding:5pt 5pt 5pt 5pt}.c18{vertical-align:top;width:104.2pt;border-style:solid;border-color:#000000;border-width:1pt;padding:5pt 5pt 5pt 5pt}.c11{vertical-align:top;width:174.8pt;border-style:solid;border-color:#000000;border-width:1pt;padding:5pt 5pt 5pt 5pt}.c1{vertical-align:top;width:189pt;border-style:solid;border-color:#000000;border-width:1pt;padding:5pt 5pt 5pt 5pt}.c19{vertical-align:top;width:181.9pt;border-style:solid;border-color:#000000;border-width:1pt;padding:5pt 5pt 5pt 5pt}.c6{vertical-align:top;width:156pt;border-style:solid;border-color:#ffffff;border-width:0pt}.c3{font-size:13pt;font-family:"Trebuchet MS";font-weight:bold}.c9{margin-right:auto;border-collapse:collapse}.c20{max-width:468pt;background-color:#ffffff;padding:72pt 72pt 72pt 72pt}.c7{color:#1155cc;text-decoration:underline}.c15{font-size:18pt;font-weight:bold}.c14{color:inherit;text-decoration:inherit}.c23{padding:5pt 5pt 5pt 5pt}.c12{font-family:"Courier New"}.c16{text-align:center}.c4{font-style:italic}.c2{line-height:1.0}.c22{height:0pt}.c5{height:11pt}.c0{direction:ltr}.c21{font-size:10pt}.title{padding-top:0pt;line-height:1.15;text-align:left;color:#000000;font-size:21pt;font-family:"Trebuchet MS";padding-bottom:0pt}.subtitle{padding-top:0pt;line-height:1.15;text-align:left;color:#666666;font-style:italic;font-size:13pt;font-family:"Trebuchet MS";padding-bottom:10pt}li{color:#000000;font-size:11pt;font-family:"Arial"}p{color:#000000;font-size:11pt;margin:0;font-family:"Arial"}h1{padding-top:10pt;line-height:1.15;text-align:left;color:#000000;font-size:16pt;font-family:"Trebuchet MS";padding-bottom:0pt}h2{padding-top:10pt;line-height:1.15;text-align:left;color:#000000;font-size:13pt;font-family:"Trebuchet MS";font-weight:bold;padding-bottom:0pt}h3{padding-top:8pt;line-height:1.15;text-align:left;color:#666666;font-size:12pt;font-family:"Trebuchet MS";font-weight:bold;padding-bottom:0pt}h4{padding-top:8pt;line-height:1.15;text-align:left;color:#666666;font-size:11pt;text-decoration:underline;font-family:"Trebuchet MS";padding-bottom:0pt}h5{padding-top:8pt;line-height:1.15;text-align:left;color:#666666;font-size:11pt;font-family:"Trebuchet MS";padding-bottom:0pt}h6{padding-top:8pt;line-height:1.15;text-align:left;color:#666666;font-style:italic;font-size:11pt;font-family:"Trebuchet MS";padding-bottom:0pt}</style></head><body class="c20"><h1 class="c16 c0"><a name="h.8569en2oflzn"></a><span class="c15">CSCI 3290 Computational Photography</span></h1><h1 class="c16 c0"><a name="h.jj2qat4gw9oo"></a><span class="c15">Assignment 1 &ndash; Image Alignment</span></h1><h5 class="c16 c0"><a name="h.978ic1c093wh"></a><span class="c21">by </span></h5><h5 class="c0 c16"><a name="h.978ic1c093wh"></a><span class="c21">7 Oct, 2013</span></h5><h1 class="c0"><a name="h.9ypnhmj3gcep"></a><span>Introduction</span></h1><p class="c5 c0"><span></span></p><p class="c0"><span class="c7"><a class="c14" href="http://www.loc.gov/pictures/collection/prok/">Prokudin-Gorskii collection</a></span><span>&nbsp;consists of a sets of three black and white photographs captured using red, green, and blue filters. This assignment is to align these images with minimized visual artifacts.</span></p><p class="c5 c0"><span></span></p><h1 class="c0"><a name="h.4ca7f94n1e3i"></a><span>Algorithm</span></h1><p class="c5 c0"><span></span></p><h2 class="c0"><a name="h.e7nv2pyt7a8c"></a><span>Sum of squared differences vs Normalized cross correlation</span></h2><p class="c5 c0"><span></span></p><p class="c0"><span>To make the alignment results contains as few visual artifacts as possible, there are two possible metrics that I have tried:</span></p><p class="c0 c5"><span></span></p><p class="c0"><span>1. Sum of squared differences (SSD): &nbsp;</span><span class="c12">sum((image1-image2).^2)</span></p><p class="c0"><span>2. Normalized cross correlation: &nbsp;</span><span class="c12">dot(image1./||image1||, image2./||image2||)</span></p><p class="c5 c0"><span></span></p><p class="c0"><span>Here is the performance test result:</span></p><p class="c5 c0"><span></span></p><a href="#" name="7cc965dda0687e33d9acdb3e9c0c3c6ae14473b0"></a><a href="#" name="0"></a><table cellpadding="0" cellspacing="0" class="c9"><tbody><tr><td class="c11"><p class="c2 c5 c0"><span></span></p></td><td class="c8"><p class="c2 c0"><span>ImgAlignSingle.m</span></p></td><td class="c8"><p class="c2 c0"><span>ImgAlignMulti.m</span></p></td><td class="c8"><p class="c2 c0"><span>ImgAlignMulti.m</span></p></td></tr><tr class="c22"><td class="c11"><p class="c2 c0"><span>Test Image</span></p></td><td class="c8"><p class="c2 c0"><span>01087u.tif</span></p></td><td class="c8"><p class="c2 c0"><span>01087v.jpg</span></p></td><td class="c8"><p class="c2 c0"><span>01087v.jpg</span></p></td></tr><tr><td class="c11"><p class="c2 c0"><span>Sum of squared differences</span></p></td><td class="c8"><p class="c2 c0"><span>17.8s</span></p></td><td class="c8"><p class="c2 c0"><span>7.8s</span></p></td><td class="c8"><p class="c2 c0"><span>0.27s</span></p></td></tr><tr><td class="c11"><p class="c2 c0"><span>Normalized cross correlation</span></p></td><td class="c8"><p class="c2 c0"><span>23.6s</span></p></td><td class="c8"><p class="c2 c0"><span>9.3s</span></p></td><td class="c8"><p class="c2 c0"><span>0.35s</span></p></td></tr></tbody></table><p class="c0"><span class="c4">Table 1 Running time of ImgAlignSingle.m and ImgAlignMulti.m</span></p><p class="c5 c0"><span></span></p><p class="c0"><span>The sum of squared differences is capable metric which can correctly align most of the images and it is very fast.</span></p><p class="c5 c0"><span></span></p><p class="c0"><span class="c3">Search range in aligning small image</span></p><p class="c5 c0"><span class="c3"></span></p><p class="c0"><span>In AlignSingle.m, I use exhaustively search over a window of possible displacements and scorc each using SSD metric. However, this method is very slow even in small image with size about 500x500. The search range is main factor which affect the total running time of the algorithm. In order to make the running be reasonable, the range is calculated by:</span></p><p class="c5 c0"><span></span></p><p class="c0"><span class="c12">range = floor(0.05 * min(height, width))</span></p><p class="c5 c0"><span class="c12"></span></p><p class="c0"><span>After several tests, 5% of the image height or width can balance the speed and accuracy of alignment.</span></p><p class="c5 c0"><span></span></p><a href="#" name="bc7b1109a76bb6c7df979e23611dd5844f0185e5"></a><a href="#" name="1"></a><table cellpadding="0" cellspacing="0" class="c9"><tbody><tr><td class="c13"><p class="c2 c0"><span>Percentage</span></p></td><td class="c10"><p class="c2 c0"><span>3%</span></p><p class="c2 c0"><img height="141" src="images/image07.jpg" width="157"></p></td><td class="c10"><p class="c2 c0"><span>4%</span></p><p class="c2 c0"><img height="144" src="images/image03.jpg" width="157"></p></td><td class="c10"><p class="c2 c0"><span>5%</span></p><p class="c2 c0"><img height="141" src="images/image13.jpg" width="157"></p></td></tr><tr><td class="c13"><p class="c2 c0"><span>Running time</span></p></td><td class="c10"><p class="c2 c0"><span>3.2s</span></p></td><td class="c10"><p class="c2 c0"><span>5.2s</span></p></td><td class="c10"><p class="c2 c0"><span>9.2s</span></p></td></tr></tbody></table><p class="c0"><span class="c4">Table 2: Running time at different search range</span></p><p class="c5 c0"><span></span></p><p class="c0"><span class="c3">Image pyramid</span></p><p class="c5 c0"><span class="c3"></span></p><p class="c0"><span>Exhaustive search will become prohibitively expensive if image resolution is too large. (For a 3000x3000 image, the search range is 5% of the height or width which equals 150px. Search with this range is really slow) To avoid this, an image pyramid is needed.</span></p><p class="c5 c0"><span></span></p><p class="c0"><span>First, we need to create multiple level of pyramid, the number of level is calculated by:</span></p><p class="c5 c0"><span></span></p><p class="c0"><span class="c12">pyramidlevel = ceil(log2(h/100))+1</span></p><p class="c5 c0"><span></span></p><p class="c0"><span>Each channel of image is blurred by using gaussian filter and subsample at every pyramid level. This produce images with different size. The we search the best displacement vector at every level. After each level of searching, update the starting position for the next search according the current best vector we found. Using the image pyramid, the search range can be a lot smaller than before. </span></p><p class="c5 c0"><span></span></p><p class="c0"><span>Moreover, I found that the speed can be improved further. At first, I can fix the search range at each level that equals to 10. The speed is still very slow. Then I changed it to 5. The performance is better but I discover that the refine process at lower level of pyramid will not change the displacement vector very much:</span></p><p class="c5 c0"><span></span></p><p class="c5 c0"><span></span></p><p class="c5 c0"><span></span></p><a href="#" name="976b5ff54911604513fb0332ea7721c576add5ef"></a><a href="#" name="2"></a><table cellpadding="0" cellspacing="0" class="c9"><tbody><tr><td class="c17"><p class="c2 c0"><span>Pyramid level</span></p></td><td class="c1"><p class="c2 c0"><span>Align Channel G to B</span></p></td><td class="c1"><p class="c0 c2"><span>Align Channel R to B</span></p></td></tr><tr><td class="c17"><p class="c2 c0"><span>7</span></p></td><td class="c1"><p class="c2 c0"><span>(1, 0)</span></p></td><td class="c1"><p class="c2 c0"><span>(3, 1)</span></p></td></tr><tr><td class="c17"><p class="c2 c0"><span>6</span></p></td><td class="c1"><p class="c2 c0"><span>(2, 1)</span></p></td><td class="c1"><p class="c2 c0"><span>(5, 1)</span></p></td></tr><tr><td class="c17"><p class="c2 c0"><span>5</span></p></td><td class="c1"><p class="c2 c0"><span>(5, 2)</span></p></td><td class="c1"><p class="c2 c0"><span>(10, 3)</span></p></td></tr><tr><td class="c17"><p class="c2 c0"><span>4</span></p></td><td class="c1"><p class="c2 c0"><span>(9, 3)</span></p></td><td class="c1"><p class="c2 c0"><span>(20, 5)</span></p></td></tr><tr><td class="c17"><p class="c2 c0"><span>3</span></p></td><td class="c1"><p class="c2 c0"><span>(19, 6)</span></p></td><td class="c1"><p class="c2 c0"><span>(41, 11)</span></p></td></tr><tr><td class="c17"><p class="c2 c0"><span>2</span></p></td><td class="c1"><p class="c2 c0"><span>(38, 12)</span></p></td><td class="c1"><p class="c2 c0"><span>(83, 22)</span></p></td></tr><tr class="c22"><td class="c17"><p class="c2 c0"><span>1</span></p></td><td class="c1"><p class="c2 c0"><span>(77, 24)</span></p></td><td class="c1"><p class="c2 c0"><span>(166, 44)</span></p></td></tr></tbody></table><p class="c0"><span class="c4">Table 3: Best displacement vector of different pyramid level (01087u.tif)</span></p><p class="c5 c0"><span></span></p><p class="c0"><span>Therefore, I reduce the search range down the pyramid level. The performance is a lot better:</span></p><p class="c5 c0"><span></span></p><a href="#" name="44958473dbf0ea166602cc5d78e4c189348f0a40"></a><a href="#" name="3"></a><table cellpadding="0" cellspacing="0" class="c9"><tbody><tr><td class="c18"><p class="c2 c0"><span>Search range</span></p></td><td class="c19"><p class="c2 c0"><span>Fixed at 5</span></p></td><td class="c19"><p class="c2 c0"><span>Reduced at every level (7 to 2)</span></p></td></tr><tr><td class="c18"><p class="c2 c0"><span>Running time</span></p></td><td class="c19"><p class="c2 c0"><span>17.3s</span></p></td><td class="c19"><p class="c2 c0"><span>50.1s</span></p></td></tr></tbody></table><p class="c0"><span class="c4">Table 4: Running time with different search range (01087u.tif)</span></p><p class="c5 c0"><span></span></p><h1 class="c0"><a name="h.2bzl27t4m84g"></a><span>Extra Credit</span></h1><p class="c5 c0"><span class="c3"></span></p><p class="c0"><span class="c3">Automatic cropping</span></p><p class="c5 c0"><span class="c3"></span></p><p class="c0"><span>To remove white, black or other color borders. This is the method I used to detect the borders or the edge between the border and the image:</span></p><p class="c5 c0"><span></span></p><p class="c0"><span>1. Convert the image to grayscale</span></p><p class="c0"><span>2. Filter the image with </span><span class="c7"><a class="c14" href="http://www.mathworks.com/help/images/ref/edge.html">Canny Method</a></span></p><p class="c0"><span>3. Detect the edge only the four region of the image (left, right, top, bottom) by counting the white pixel. While searching the border region from outside to inside. If number of white pixel is larger than a certain threshold, this is considered as an border</span></p><p class="c0"><span>4. Crop the image according the coordinates searched</span></p><p class="c0"><span>5. If the input image is too large, first resize the image to about 500x500</span></p><p class="c0"><span>6. This method assume that the border is horizontal or vertical.</span></p><p class="c0"><span>7. This algorithm of cropping will leave some color border. But I think it is better than over cropping. </span></p><a href="#" name="e4d10381407d1f819cbbad4015c907c638657fc3"></a><a href="#" name="4"></a><table cellpadding="0" cellspacing="0" class="c9"><tbody><tr><td class="c6 c23"><p class="c2 c0"><img height="175" src="images/image15.jpg" width="196"></p><p class="c2 c0"><span class="c4">Picture 1: Orignal image</span></p></td><td class="c6"><p class="c2 c0"><img height="178" src="images/image08.jpg" width="205"></p><p class="c2 c0"><span class="c4">Picture 2: Canny edge of the image</span></p></td><td class="c6 c23"><p class="c2 c0"><img height="170" src="images/image01.jpg" width="193"></p><p class="c2 c0"><span class="c4">Picture 3: Cropped image</span></p></td></tr></tbody></table><p class="c5 c0"><span></span></p><p class="c0"><span class="c3">Automatic contrasting</span></p><p class="c5 c0"><span class="c3"></span></p><p class="c0"><span>The input image has 3 color channels. For each color channel, reshape the matrix to 1D array and then sort them all. Pixels which under 0.05% and above 99.95% are removed. The remaining pixels is then rescaled in order to stretch the color range back to 0-255. Then the contrast of final image is improved. Besides, the threshold can be automatically push to maximum using the the function of </span><span class="c7"><a class="c14" href="http://www.mathworks.com/help/images/ref/stretchlim.html">Matlab</a></span><span>.</span></p><p class="c5 c0"><span></span></p><p class="c0"><span class="c3">Calculate metrics using image gradient</span></p><p class="c5 c0"><span></span></p><p class="c0"><span>Instead of aligning based on RGB similarity, convert the image to gradients before searching displacement vector can improve performance. Image gradient is effective for large image. But if the image has many noises and the size is small, this method will cause some bad alignment.</span></p><p class="c5 c0"><span></span></p><h1 class="c0"><a name="h.5ok2oop8pwyi"></a><span>Results</span></h1><p class="c5 c0"><span></span></p><h2 class="c0"><a name="h.a4ywtisw3uho"></a><span>Low resolution</span></h2><p class="c5 c0"><span class="c4"></span></p><p class="c0"><img height="320" src="images/image14.jpg" width="360"></p><p class="c0"><span class="c4">00082v.jpg</span></p><p class="c0"><img height="320" src="images/image05.jpg" width="364"></p><p class="c0"><span class="c4">00194v.jpg</span></p><p class="c0"><img height="319" src="images/image02.jpg" width="355"></p><p class="c0"><span class="c4">00270v.jpg</span></p><p class="c0"><img height="317" src="images/image11.jpg" width="360"></p><p class="c0"><span class="c4">00542v.jpg</span></p><p class="c0"><img height="314" src="images/image09.jpg" width="353"></p><p class="c0"><span class="c4">01779v.jpg</span></p><p class="c5 c0"><span class="c4"></span></p><h2 class="c0"><a name="h.1y8ufkngi0d7"></a><span>High resolution (Scaled)</span></h2><p class="c5 c0"><span class="c4"></span></p><p class="c0"><img height="449" src="images/image12.jpg" width="519"></p><p class="c0"><span class="c4">00014u.tif</span></p><p class="c0"><img height="437" src="images/image10.jpg" width="499"></p><p class="c0"><span class="c4">00069u.tif</span></p><p class="c0"><img height="445" src="images/image00.jpg" width="503"></p><p class="c0"><span class="c4">00086u.tif</span></p><p class="c0"><img height="464" src="images/image06.jpg" width="530"></p><p class="c0"><span class="c4">00104u.tif</span></p><p class="c0"><img height="450" src="images/image04.jpg" width="502"></p><p class="c0"><span class="c4">00157u.tif</span></p><p class="c5 c0"><span></span></p><h1 class="c0"><a name="h.f9qkfula7kg2"></a><span>Reference</span></h1><p class="c5 c0"><span class="c3"></span></p><p class="c0"><span class="c7"><a class="c14" href="http://en.wikipedia.org/wiki/Sergey_Prokudin-Gorsky">http://en.wikipedia.org/wiki/Sergey_Prokudin-Gorsky</a></span></p><p class="c0"><span class="c7"><a class="c14" href="http://www.mathworks.com/help/images/ref/edge.html">http://www.mathworks.com/help/images/ref/edge.html</a></span></p><p class="c0"><span class="c7"><a class="c14" href="http://www.mathworks.com/help/images/ref/stretchlim.html">http://www.mathworks.com/help/images/ref/stretchlim.html</a></span></p><p class="c5 c0"><span></span></p></body></html>
